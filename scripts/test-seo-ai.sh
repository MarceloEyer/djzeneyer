#!/bin/bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª SCRIPTS DE TESTE E VALIDAÃ‡ÃƒO - DJ ZEN EYER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Use estes scripts para testar seu robots.txt e configuraÃ§Ãµes de IA
# Salve como: test-seo-ai.sh
# Uso: chmod +x test-seo-ai.sh && ./test-seo-ai.sh
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SITE_URL="https://djzeneyer.com"
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§ª TESTE DE SEO E IA - DJ ZEN EYER"
echo "Site: $SITE_URL"
echo "Data: $(date)"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. TESTE DE ROBOTS.TXT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ“„ Testando robots.txt..."
ROBOTS_HTTP=$(curl -s -o /dev/null -w "%{http_code}" "$SITE_URL/robots.txt")

if [ "$ROBOTS_HTTP" = "200" ]; then
    echo -e "${GREEN}âœ… robots.txt acessÃ­vel (HTTP $ROBOTS_HTTP)${NC}"
    
    # Baixar e validar conteÃºdo
    ROBOTS_CONTENT=$(curl -s "$SITE_URL/robots.txt")
    
    # Verificar diretivas essenciais
    if echo "$ROBOTS_CONTENT" | grep -q "User-agent:"; then
        echo -e "${GREEN}  âœ… ContÃ©m User-agent${NC}"
    else
        echo -e "${RED}  âŒ Sem User-agent${NC}"
    fi
    
    if echo "$ROBOTS_CONTENT" | grep -q "Sitemap:"; then
        echo -e "${GREEN}  âœ… ContÃ©m Sitemap${NC}"
        SITEMAP_URL=$(echo "$ROBOTS_CONTENT" | grep "Sitemap:" | head -1 | awk '{print $2}')
        echo "     URL: $SITEMAP_URL"
    else
        echo -e "${YELLOW}  âš ï¸  Sem declaraÃ§Ã£o de Sitemap${NC}"
    fi
    
    # Verificar diretivas NÃƒO-OFICIAIS (devem estar ausentes)
    if echo "$ROBOTS_CONTENT" | grep -q "AI-Training-Data:\|Request-rate:\|Model-Instruction:"; then
        echo -e "${RED}  âŒ ERRO: ContÃ©m diretivas nÃ£o-oficiais!${NC}"
        echo "     Remova: AI-Training-Data, Request-rate, Model-Instruction"
    else
        echo -e "${GREEN}  âœ… Sem diretivas nÃ£o-oficiais${NC}"
    fi
    
    # Verificar bots de IA
    if echo "$ROBOTS_CONTENT" | grep -q "GPTBot\|ClaudeBot\|Claude-Web"; then
        echo -e "${GREEN}  âœ… Configurado para bots de IA${NC}"
    else
        echo -e "${YELLOW}  âš ï¸  Sem configuraÃ§Ã£o especÃ­fica para IAs${NC}"
    fi
else
    echo -e "${RED}âŒ robots.txt inacessÃ­vel (HTTP $ROBOTS_HTTP)${NC}"
fi

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. TESTE DE AI-PLUGIN.JSON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ¤– Testando .well-known/ai-plugin.json..."
AI_PLUGIN_HTTP=$(curl -s -o /dev/null -w "%{http_code}" "$SITE_URL/.well-known/ai-plugin.json")

if [ "$AI_PLUGIN_HTTP" = "200" ]; then
    echo -e "${GREEN}âœ… ai-plugin.json acessÃ­vel (HTTP $AI_PLUGIN_HTTP)${NC}"
    
    # Baixar e validar JSON
    AI_PLUGIN_CONTENT=$(curl -s "$SITE_URL/.well-known/ai-plugin.json")
    
    # Verificar se Ã© JSON vÃ¡lido
    if echo "$AI_PLUGIN_CONTENT" | jq . > /dev/null 2>&1; then
        echo -e "${GREEN}  âœ… JSON vÃ¡lido${NC}"
        
        # Extrair campos importantes
        NAME=$(echo "$AI_PLUGIN_CONTENT" | jq -r '.name_for_human // empty')
        DESC=$(echo "$AI_PLUGIN_CONTENT" | jq -r '.description_for_model // empty')
        
        if [ -n "$NAME" ]; then
            echo "     Nome: $NAME"
        fi
        if [ -n "$DESC" ]; then
            echo "     DescriÃ§Ã£o: ${DESC:0:80}..."
        fi
    else
        echo -e "${RED}  âŒ JSON invÃ¡lido${NC}"
    fi
else
    echo -e "${YELLOW}âš ï¸  ai-plugin.json nÃ£o encontrado (HTTP $AI_PLUGIN_HTTP)${NC}"
    echo "   Considere criar: $SITE_URL/.well-known/ai-plugin.json"
fi

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. TESTE DE SITEMAPS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ—ºï¸  Testando sitemaps..."

SITEMAPS=(
    "sitemap.xml"
    "sitemap_index.xml"
    "sitemap-pages.xml"
    "sitemap-posts.xml"
    "sitemap-products.xml"
)

for sitemap in "${SITEMAPS[@]}"; do
    SITEMAP_HTTP=$(curl -s -o /dev/null -w "%{http_code}" "$SITE_URL/$sitemap")
    
    if [ "$SITEMAP_HTTP" = "200" ]; then
        echo -e "${GREEN}  âœ… $sitemap (HTTP $SITEMAP_HTTP)${NC}"
        
        # Contar URLs
        URL_COUNT=$(curl -s "$SITE_URL/$sitemap" | grep -o "<loc>" | wc -l)
        echo "     URLs: $URL_COUNT"
    else
        echo -e "${YELLOW}  â„¹ï¸  $sitemap nÃ£o encontrado (HTTP $SITEMAP_HTTP)${NC}"
    fi
done

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. TESTE DE META TAGS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ·ï¸  Testando meta tags..."
HTML=$(curl -s "$SITE_URL/")

# Verificar meta robots
if echo "$HTML" | grep -q '<meta name="robots"'; then
    echo -e "${GREEN}  âœ… Meta robots presente${NC}"
    META_ROBOTS=$(echo "$HTML" | grep '<meta name="robots"' | head -1)
    echo "     $META_ROBOTS"
else
    echo -e "${YELLOW}  âš ï¸  Meta robots ausente${NC}"
fi

# Verificar OpenGraph
if echo "$HTML" | grep -q '<meta property="og:'; then
    echo -e "${GREEN}  âœ… OpenGraph tags presentes${NC}"
else
    echo -e "${YELLOW}  âš ï¸  OpenGraph tags ausentes${NC}"
fi

# Verificar JSON-LD
if echo "$HTML" | grep -q 'application/ld+json'; then
    echo -e "${GREEN}  âœ… JSON-LD structured data presente${NC}"
    JSON_LD_COUNT=$(echo "$HTML" | grep -o 'application/ld+json' | wc -l)
    echo "     Schemas: $JSON_LD_COUNT"
else
    echo -e "${YELLOW}  âš ï¸  JSON-LD structured data ausente${NC}"
fi

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. TESTE DE CRAWLING COMO BOTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ¤– Testando acesso de bots..."

BOTS=(
    "Googlebot:Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"
    "GPTBot:Mozilla/5.0 (compatible; GPTBot/1.0; +https://openai.com/gptbot)"
    "ClaudeBot:Mozilla/5.0 (compatible; ClaudeBot/1.0; +https://www.anthropic.com)"
)

for bot in "${BOTS[@]}"; do
    BOT_NAME="${bot%%:*}"
    USER_AGENT="${bot#*:}"
    
    BOT_HTTP=$(curl -s -o /dev/null -w "%{http_code}" -A "$USER_AGENT" "$SITE_URL/")
    
    if [ "$BOT_HTTP" = "200" ]; then
        echo -e "${GREEN}  âœ… $BOT_NAME pode acessar (HTTP $BOT_HTTP)${NC}"
    else
        echo -e "${RED}  âŒ $BOT_NAME bloqueado (HTTP $BOT_HTTP)${NC}"
    fi
done

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. TESTE DE PERFORMANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "âš¡ Testando performance..."

# Tempo de resposta
RESPONSE_TIME=$(curl -o /dev/null -s -w '%{time_total}\n' "$SITE_URL/")
RESPONSE_TIME_MS=$(echo "$RESPONSE_TIME * 1000" | bc)

if (( $(echo "$RESPONSE_TIME < 2.0" | bc -l) )); then
    echo -e "${GREEN}  âœ… Tempo de resposta: ${RESPONSE_TIME}s${NC}"
elif (( $(echo "$RESPONSE_TIME < 4.0" | bc -l) )); then
    echo -e "${YELLOW}  âš ï¸  Tempo de resposta: ${RESPONSE_TIME}s (considere otimizar)${NC}"
else
    echo -e "${RED}  âŒ Tempo de resposta: ${RESPONSE_TIME}s (muito lento!)${NC}"
fi

# HTTPS
if curl -s "$SITE_URL/" | grep -q "https"; then
    echo -e "${GREEN}  âœ… HTTPS funcionando${NC}"
else
    echo -e "${YELLOW}  âš ï¸  Verifique configuraÃ§Ã£o HTTPS${NC}"
fi

# CompressÃ£o
COMPRESSION=$(curl -s -I -H "Accept-Encoding: gzip" "$SITE_URL/" | grep -i "content-encoding")
if echo "$COMPRESSION" | grep -q "gzip"; then
    echo -e "${GREEN}  âœ… CompressÃ£o gzip ativa${NC}"
else
    echo -e "${YELLOW}  âš ï¸  CompressÃ£o gzip desativada${NC}"
fi

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. TESTE DE WORDPRESS REST API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "ğŸ”Œ Testando WordPress REST API..."

REST_HTTP=$(curl -s -o /dev/null -w "%{http_code}" "$SITE_URL/wp-json/")
if [ "$REST_HTTP" = "200" ]; then
    echo -e "${GREEN}  âœ… REST API acessÃ­vel (HTTP $REST_HTTP)${NC}"
    
    # Testar endpoint customizado
    CUSTOM_API_HTTP=$(curl -s -o /dev/null -w "%{http_code}" "$SITE_URL/wp-json/djz/v1/ai-data")
    if [ "$CUSTOM_API_HTTP" = "200" ]; then
        echo -e "${GREEN}  âœ… Endpoint /djz/v1/ai-data funcionando${NC}"
    else
        echo -e "${YELLOW}  â„¹ï¸  Endpoint /djz/v1/ai-data nÃ£o encontrado (HTTP $CUSTOM_API_HTTP)${NC}"
    fi
else
    echo -e "${RED}  âŒ REST API inacessÃ­vel (HTTP $REST_HTTP)${NC}"
fi

echo ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. RESUMO FINAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ“Š RESUMO DO TESTE"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

TOTAL_CHECKS=0
PASSED_CHECKS=0

# Contadores (ajuste conforme os testes acima)
if [ "$ROBOTS_HTTP" = "200" ]; then ((PASSED_CHECKS++)); fi
((TOTAL_CHECKS++))

if [ "$AI_PLUGIN_HTTP" = "200" ]; then ((PASSED_CHECKS++)); fi
((TOTAL_CHECKS++))

PASS_RATE=$(echo "scale=0; $PASSED_CHECKS * 100 / $TOTAL_CHECKS" | bc)

echo ""
echo "VerificaÃ§Ãµes: $PASSED_CHECKS/$TOTAL_CHECKS passaram ($PASS_RATE%)"
echo ""

if [ $PASS_RATE -ge 80 ]; then
    echo -e "${GREEN}ğŸ‰ Excelente! Seu site estÃ¡ bem otimizado para SEO e IAs${NC}"
elif [ $PASS_RATE -ge 50 ]; then
    echo -e "${YELLOW}âš ï¸  Bom, mas hÃ¡ melhorias a fazer${NC}"
else
    echo -e "${RED}âŒ AtenÃ§Ã£o! VÃ¡rias otimizaÃ§Ãµes necessÃ¡rias${NC}"
fi

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "Para mais informaÃ§Ãµes, consulte:"
echo "  - Google Search Console: https://search.google.com/search-console"
echo "  - Schema Validator: https://validator.schema.org/"
echo "  - PageSpeed: https://pagespeed.web.dev/"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
