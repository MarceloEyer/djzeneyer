# ==============================================================================
# üéµ DJ ZEN EYER - ROBOTS.TXT (RFC 9309 COMPLIANT)
# ==============================================================================
# √öltima atualiza√ß√£o: 2025-01-03
# Prop√≥sito: SEO otimizado + crawling inteligente para buscadores e IAs
# Padr√£o: RFC 9309 (Robots Exclusion Protocol)
# Valida√ß√£o: https://www.google.com/webmasters/tools/robots-testing-tool
# ==============================================================================

# ==============================================================================
# üìò DOCUMENTA√á√ÉO: O QUE √â CADA DIRETIVA
# ==============================================================================
# 
# User-agent: Define qual bot/crawler esta regra se aplica
#   - Use "*" para todos os bots
#   - Use nome espec√≠fico (ex: "Googlebot") para regras individuais
#   - M√∫ltiplos User-agent seguidos aplicam as mesmas regras
#
# Allow: Permite acesso expl√≠cito a um caminho
#   - √ötil para liberar subdiret√≥rios dentro de um Disallow
#   - Exemplo: Allow: /wp-admin/admin-ajax.php
#
# Disallow: Bloqueia acesso a um caminho
#   - Disallow: / = bloqueia tudo
#   - Disallow: (vazio) = permite tudo
#   - Usa wildcards: * (qualquer string) e $ (fim da URL)
#
# Crawl-delay: Tempo m√≠nimo (em segundos) entre requisi√ß√µes
#   - N√ÉO suportado por Google/Bing (use Google Search Console)
#   - Suportado por Bing, Yandex e alguns bots menores
#   - Valor recomendado: 1-10 segundos
#
# Sitemap: URL do sitemap XML
#   - Obrigat√≥rio para SEO
#   - Pode ter m√∫ltiplas linhas Sitemap
#
# ==============================================================================

# ==============================================================================
# üåê REGRA PADR√ÉO (TODOS OS BOTS)
# ==============================================================================
# Esta se√ß√£o se aplica a todos os crawlers que n√£o t√™m regras espec√≠ficas
User-agent: *

# Permitir acesso total ao site
Allow: /

# Bloquear WordPress Admin e √°reas privadas
Disallow: /wp-admin/
Disallow: /wp-login.php
Disallow: /wp-includes/

# Permitir AJAX do WordPress (necess√°rio para funcionalidades)
Allow: /wp-admin/admin-ajax.php

# Bloquear arquivos de sistema WordPress
Disallow: /xmlrpc.php
Disallow: /wp-config.php
Disallow: /readme.html
Disallow: /license.txt
Disallow: /wp-trackback.php

# Bloquear diret√≥rios t√©cnicos
Disallow: /cgi-bin/
Disallow: /.git/
Disallow: /node_modules/
Disallow: /.env

# Bloquear p√°ginas de busca e filtros (conte√∫do duplicado)
Disallow: /*?s=*              # Busca WordPress
Disallow: /*?s$               # Busca WordPress (fim da URL)
Disallow: /search/            # P√°gina de busca
Disallow: /*?*sort=*          # Par√¢metros de ordena√ß√£o
Disallow: /*?*filter=*        # Par√¢metros de filtro
Disallow: /*?*page=*          # Pagina√ß√£o (se gera duplica√ß√£o)

# Bloquear p√°ginas de e-commerce privadas (WooCommerce)
Disallow: /cart/
Disallow: /checkout/
Disallow: /my-account/
Disallow: /wc-api/

# Bloquear trackbacks e coment√°rios
Disallow: /trackback/
Disallow: /*/trackback$
Disallow: /*/feed/
Disallow: /comments/feed/

# Permitir uploads e assets (imagens, v√≠deos, CSS, JS)
Allow: /wp-content/uploads/
Allow: /wp-content/themes/*/assets/
Allow: /wp-content/themes/*/dist/
Allow: /assets/
Allow: /images/
Allow: /fonts/
Allow: /css/
Allow: /js/

# Crawl-delay para bots gen√©ricos (n√£o afeta Google/Bing)
Crawl-delay: 1

# ==============================================================================
# ü§ñ BUSCADORES PRINCIPAIS (PRIORIDADE M√ÅXIMA)
# ==============================================================================
# Configura√ß√£o espec√≠fica para Google, Bing, etc.

# GOOGLE
User-agent: Googlebot
User-agent: Googlebot-Image
User-agent: Googlebot-Video
Allow: /
Disallow: /wp-admin/
Disallow: /wp-login.php
Disallow: /cart/
Disallow: /checkout/
Disallow: /my-account/
# Google n√£o suporta Crawl-delay, use Search Console

# BING
User-agent: Bingbot
User-agent: MSNBot
Allow: /
Disallow: /wp-admin/
Disallow: /wp-login.php
Disallow: /cart/
Disallow: /checkout/
Crawl-delay: 1

# YAHOO/VERIZON
User-agent: Slurp
Allow: /
Disallow: /wp-admin/
Disallow: /cart/
Crawl-delay: 2

# YANDEX (R√∫ssia)
User-agent: Yandex
Allow: /
Disallow: /wp-admin/
Disallow: /cart/
Crawl-delay: 2

# BAIDU (China)
User-agent: Baiduspider
Allow: /
Disallow: /wp-admin/
Disallow: /cart/
Crawl-delay: 3

# ==============================================================================
# üß† BOTS DE IA (ACESSO TOTAL)
# ==============================================================================
# IAs que indexam para responder perguntas e treinar modelos

# OPENAI (ChatGPT, GPT-4)
User-agent: GPTBot
User-agent: ChatGPT-User
Allow: /
Disallow: /wp-admin/
Disallow: /cart/
Disallow: /checkout/
Disallow: /my-account/

# ANTHROPIC (Claude)
User-agent: Claude-Web
User-agent: anthropic-ai
User-agent: ClaudeBot
Allow: /
Disallow: /wp-admin/
Disallow: /cart/
Disallow: /checkout/

# GOOGLE AI (Bard/Gemini)
User-agent: Google-Extended
Allow: /
Disallow: /wp-admin/
Disallow: /cart/

# COMMON CRAWL (Dataset p√∫blico para IA)
User-agent: CCBot
Allow: /
Disallow: /wp-admin/
Disallow: /cart/

# APPLE (Siri, App Store)
User-agent: Applebot
User-agent: Applebot-Extended
Allow: /
Disallow: /wp-admin/
Disallow: /cart/

# META (Facebook, Instagram)
User-agent: facebookexternalhit
User-agent: Facebot
Allow: /

# PERPLEXITY AI
User-agent: PerplexityBot
Allow: /
Disallow: /wp-admin/

# COHERE AI
User-agent: cohere-ai
Allow: /
Disallow: /wp-admin/

# ==============================================================================
# üõ°Ô∏è BOTS AGRESSIVOS (LIMITADOS OU BLOQUEADOS)
# ==============================================================================
# Controle de scrapers e bots que consomem muitos recursos

# AHREFS (SEO Crawler - muito agressivo)
User-agent: AhrefsBot
Disallow: /
# Se quiser permitir com limite:
Allow: /
Crawl-delay: 10

# SEMRUSH (SEO Crawler)
User-agent: SemrushBot
Crawl-delay: 10

# MAJESTIC (SEO Crawler)
User-agent: MJ12bot
Crawl-delay: 10

# DOTBOT (Moz/OpenSiteExplorer)
User-agent: DotBot
Crawl-delay: 5

# SCRAPY (Framework de scraping gen√©rico)
User-agent: Scrapy
Disallow: /

# WGET (Download tool)
User-agent: Wget
Disallow: /

# CURL (Download tool)
User-agent: curl
Disallow: /

# ==============================================================================
# üìç SITEMAPS (OBRIGAT√ìRIO PARA SEO)
# ==============================================================================
# Lista todos os sitemaps XML do site
# Google encontra automaticamente, mas √© bom declarar

Sitemap: https://djzeneyer.com/sitemap.xml
Sitemap: https://djzeneyer.com/sitemap-pages.xml

# ==============================================================================
# üìö REFER√äNCIAS E BOAS PR√ÅTICAS
# ==============================================================================
#
# PADR√ïES OFICIAIS:
# - RFC 9309: https://www.rfc-editor.org/rfc/rfc9309.html
# - Google: https://developers.google.com/search/docs/crawling-indexing/robots/intro
# - Bing: https://www.bing.com/webmasters/help/how-to-create-a-robots-txt-file-cb7c31ec
#
# DIRETIVAS SUPORTADAS (RFC 9309):
# ‚úÖ User-agent
# ‚úÖ Allow
# ‚úÖ Disallow
# ‚úÖ Sitemap
# ‚ö†Ô∏è  Crawl-delay (n√£o-oficial, mas amplamente suportado)
#
# DIRETIVAS N√ÉO-PADR√ÉO (N√ÉO USE):
# ‚ùå Request-rate (use servidor/CDN)
# ‚ùå AI-Training-Data (use meta tags ou API)
# ‚ùå Visit-time (n√£o existe)
# ‚ùå Noindex (use meta tags no HTML)
# ‚ùå Nofollow (use meta tags no HTML)
#
# VALIDA√á√ÉO:
# - Google Search Console: https://search.google.com/search-console
# - Bing Webmaster: https://www.bing.com/webmasters
# - Validators: https://www.seobility.net/robots-txt/
#
# NOTAS:
# - Este arquivo √© case-sensitive
# - Ordem importa: regras mais espec√≠ficas primeiro
# - Wildcards: * (qualquer string), $ (fim de URL)
# - Coment√°rios come√ßam com #
# - Linhas em branco s√£o ignoradas
#
# PARA IAs: Veja /.well-known/ai-plugin.json para metadados estruturados
# ==============================================================================
